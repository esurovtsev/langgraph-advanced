{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b0b325",
   "metadata": {},
   "source": [
    "# Task Reasoning in LangGraph: Intelligent Agent Delegation with Shared Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9c4cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "def print_messages(messages, truncate_length=200):\n",
    "    \"\"\"\n",
    "    Print messages with truncation for long tool message content.\n",
    "    \n",
    "    Args:\n",
    "        messages: List of LangChain messages to print\n",
    "        truncate_length: Maximum length before truncating tool message content\n",
    "    \"\"\"\n",
    "    for message in messages:\n",
    "        if isinstance(message, ToolMessage):\n",
    "            print(f\"=================================[1m Tool Message [0m=================================\")\n",
    "            print(f\"Name: {message.name}\\n\")\n",
    "            \n",
    "            # Truncate long content\n",
    "            content = message.content\n",
    "            if len(content) > truncate_length:\n",
    "                print(f\"{content[:truncate_length]}...\\n[Content truncated - {len(content)} chars total]\")\n",
    "            else:\n",
    "                print(content)\n",
    "        else:\n",
    "            # Use pretty_print for AI and Human messages\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d56db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_tavily import TavilySearch\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from pprint import pformat\n",
    "from datetime import datetime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "import uuid\n",
    "\n",
    "_GLOBAL_STORE = None\n",
    "\n",
    "def initialize_store(store):\n",
    "    global _GLOBAL_STORE\n",
    "    _GLOBAL_STORE = store\n",
    "\n",
    "def get_global_store():\n",
    "    return _GLOBAL_STORE\n",
    "\n",
    "initialize_store(InMemoryStore())\n",
    "\n",
    "\n",
    "FORBIDDEN_KEYWORDS = {\n",
    "    \"403 forbidden\", \"access denied\", \"captcha\",\n",
    "    \"has been denied\", \"not authorized\", \"verify you are a human\"\n",
    "}\n",
    "\n",
    "@tool\n",
    "def web_search(query: str, max_results: int = 5) -> Dict[str, List[Dict[str, str]]]:\n",
    "    \"\"\"\n",
    "    General-purpose web search.\n",
    "\n",
    "    Use when you need recent or broader information from the web to answer the user's request\n",
    "    (e.g., discover relevant entities, find supporting context, or gather up-to-date references).\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The search query in plain language.\n",
    "    - max_results (int): Number of results to return (default 5, max 10).\n",
    "\n",
    "    Returns:\n",
    "    - {\"results\": [{\"title\": str, \"url\": str, \"snippet\": str}, ...]}\n",
    "\n",
    "    Example:\n",
    "    - query: \"emerging AI hardware companies\"\n",
    "    \"\"\"\n",
    "    max_results = max(1, min(max_results, 10))\n",
    "    tavily = TavilySearch(max_results=max_results)\n",
    "    raw = tavily.invoke({\"query\": query})\n",
    "\n",
    "    results = [\n",
    "        {k: v for k, v in page.items() if k != \"raw_content\"}  # drop heavy field\n",
    "        for page in raw[\"results\"]\n",
    "        if not any(\n",
    "            k in ((page.get(\"content\") or \"\").lower())\n",
    "            for k in FORBIDDEN_KEYWORDS\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return {\"results\": results}\n",
    "\n",
    "\n",
    "@tool\n",
    "def wiki_search(topic: str, max_results: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Fetch a concise encyclopedic summary for a single entity or topic.\n",
    "\n",
    "    When to use:\n",
    "      - You need neutral background about a company, product, person, or concept.\n",
    "\n",
    "    How to format `topic` (VERY IMPORTANT):\n",
    "      - Pass a short, Wikipedia-friendly title or entity name.\n",
    "      - Avoid questions or long queries. Prefer canonical forms.\n",
    "      - If you have noisy text, reduce it to the key noun phrase.\n",
    "\n",
    "    Good examples:\n",
    "      - \"NVIDIA\", \"OpenAI\", \"Large language model\", \"Electric vehicle\"\n",
    "    Avoid:\n",
    "      - \"What is NVIDIA and why is it important?\", \"tell me about AI chips 2025\"\n",
    "\n",
    "    Parameters:\n",
    "      - topic (str): Canonical page title or concise entity/topic.\n",
    "    \"\"\"\n",
    "    max_results = max(1, min(max_results, 10))\n",
    "    wiki = WikipediaLoader(query=topic, load_max_docs=max_results)\n",
    "    raw = wiki.load()\n",
    "\n",
    "    results = [\n",
    "      {\n",
    "        \"title\": doc.metadata[\"title\"],\n",
    "        \"summary\": doc.metadata[\"summary\"],\n",
    "        \"source\": doc.metadata[\"source\"]\n",
    "      }\n",
    "      for doc in raw\n",
    "    ]\n",
    "\n",
    "    return {\"results\": results}\n",
    "\n",
    "\n",
    "@tool(\"lookup_stock\")\n",
    "def lookup_stock_symbol(company_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a company name to its stock symbol using a financial API.\n",
    "\n",
    "    Parameters:\n",
    "        company_name (str): The full company name (e.g., 'Tesla').\n",
    "\n",
    "    Returns:\n",
    "        str: The stock symbol (e.g., 'TSLA') or an error message.\n",
    "    \"\"\"\n",
    "    api_url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"SYMBOL_SEARCH\",\n",
    "        \"keywords\": company_name,\n",
    "        \"apikey\": \"your_alphavantage_api_key\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"bestMatches\" in data and data[\"bestMatches\"]:\n",
    "        return data[\"bestMatches\"][0][\"1. symbol\"]\n",
    "    else:\n",
    "        return f\"Symbol not found for {company_name}.\"\n",
    "\n",
    "\n",
    "@tool(\"fetch_stock_data\")\n",
    "def fetch_stock_data_raw(stock_symbol: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetches comprehensive stock data for a given symbol and returns it as a combined dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        stock_symbol (str): The stock ticker symbol (e.g., 'TSLA').\n",
    "        period (str): The period to analyze (e.g., '1mo', '3mo', '1y').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary combining general stock info and historical market data.\n",
    "    \"\"\"\n",
    "    period = \"1mo\"\n",
    "    try:\n",
    "        stock = yf.Ticker(stock_symbol)\n",
    "\n",
    "        # Retrieve general stock info and historical market data\n",
    "        stock_info = stock.info  # Basic company and stock data\n",
    "        stock_history = stock.history(period=period).to_dict()  # Historical OHLCV data\n",
    "\n",
    "        # Combine both into a single dictionary\n",
    "        combined_data = {\n",
    "            \"stock_symbol\": stock_symbol,\n",
    "            \"info\": stock_info,\n",
    "            \"history\": stock_history\n",
    "        }\n",
    "\n",
    "        return pformat(combined_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error fetching stock data for {stock_symbol}: {str(e)}\"}\n",
    "\n",
    "\n",
    "@tool\n",
    "def place_order(\n",
    "    symbol: str,\n",
    "    action: str,\n",
    "    shares: int,\n",
    "    limit_price: float,\n",
    "    order_type: str = \"limit\",\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Execute a stock order.\n",
    "\n",
    "    Parameters:\n",
    "    - symbol: Ticker\n",
    "    - action: \"buy\" or \"sell\"\n",
    "    - shares: Number of shares to trade (pre-computed by the agent)\n",
    "    - limit_price: Limit price per share\n",
    "    - order_type: Order type, default \"limit\"\n",
    "\n",
    "    Returns:\n",
    "    - status: Execution result (simulated)\n",
    "    - symbol\n",
    "    - shares\n",
    "    - limit_price\n",
    "    - total_spent\n",
    "    - type: Order type used\n",
    "    - action\n",
    "    \"\"\"\n",
    "    total_spent = round(int(shares) * limit_price, 2)\n",
    "    return {\n",
    "        \"status\": \"filled\",\n",
    "        \"symbol\": symbol,\n",
    "        \"shares\": int(shares),\n",
    "        \"limit_price\": limit_price,\n",
    "        \"total_spent\": total_spent,\n",
    "        \"type\": order_type,\n",
    "        \"action\": action,\n",
    "    }\n",
    "\n",
    "\n",
    "@tool\n",
    "def current_timestamp() -> dict:\n",
    "    \"\"\"\n",
    "    Return the current local timestamp.\n",
    "\n",
    "    Returns:\n",
    "    - {\"iso\": str, \"epoch\": int, \"tz\": str}\n",
    "      where:\n",
    "      - iso: ISO 8601 string with timezone offset\n",
    "      - epoch: Unix epoch seconds\n",
    "      - tz: timezone name/offset\n",
    "    \"\"\"\n",
    "    now = datetime.now().astimezone()\n",
    "    return {\n",
    "        \"iso\": now.isoformat(),\n",
    "        \"epoch\": int(now.timestamp()),\n",
    "        \"tz\": str(now.tzinfo),\n",
    "    }\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_order_history(config: RunnableConfig) -> list:\n",
    "    \"\"\"\n",
    "    Retrieves past investment orders for the current user.\n",
    "    \n",
    "    Returns:\n",
    "        A list of past orders with details including order_id, timestamp, symbol, shares, and price\n",
    "        \n",
    "    Example Usage: \n",
    "        Review previous investments before recommending new ones\n",
    "    \"\"\"\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    namespace = (\"ledger\", user_id)\n",
    "    store = get_global_store()\n",
    "    items = store.search(namespace)\n",
    "    return [item.value for item in items]\n",
    "    \n",
    "\n",
    "@tool\n",
    "def add_order_to_history(symbol: str, shares: int, price: float, config: RunnableConfig) -> dict:\n",
    "    \"\"\"\n",
    "    Records a new investment order in the user's order history.\n",
    "    \n",
    "    Args:\n",
    "        symbol: Stock ticker symbol (e.g., 'AAPL', 'MSFT')\n",
    "        shares: Number of shares purchased or sold (positive for buy, negative for sell)\n",
    "        price: Price per share in USD\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the newly created order details including order_id and timestamp\n",
    "        \n",
    "    Example:\n",
    "        To record a purchase of 10 shares of Apple at $190.50:\n",
    "        add_order_to_history(symbol='AAPL', shares=10, price=190.50)\n",
    "    \"\"\"\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    namespace = (\"ledger\", user_id)\n",
    "    store = get_global_store()\n",
    "\n",
    "    order_id = str(uuid.uuid4())\n",
    "    order = {\n",
    "        \"order_id\": order_id,\n",
    "        \"ts\": datetime.now().isoformat(),\n",
    "        \"symbol\": symbol,\n",
    "        \"shares\": shares,\n",
    "        \"price\": price\n",
    "    }\n",
    "    store.put(namespace, order_id, order)\n",
    "\n",
    "    return order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042d1fb5",
   "metadata": {},
   "source": [
    "## research_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Image, display\n",
    "\n",
    "RESEARCH_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a Research Agent that recommends ONE promising company for investment based on user requests.\n",
    "\n",
    "Find a company that matches the user's theme/sector. Use tools to verify information. Be factual and concise.\n",
    "\n",
    "Rules:\n",
    "- Recommend exactly ONE company that is publicly tradable\n",
    "- **Important!** ensure that the company you recommend is is publicly tradable!\n",
    "- Make 2-3 tool calls maximum\n",
    "- Don't place trades or fabricate data\n",
    "- End with: CHOSEN_COMPANY: <Company Name>\n",
    "\n",
    "Output a 1-2 sentence explanation followed by the company name.\n",
    "\"\"\"\n",
    "\n",
    "research = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[web_search, wiki_search],\n",
    "    prompt=RESEARCH_SYSTEM_MESSAGE,\n",
    "\n",
    "    name=\"research\"\n",
    ")\n",
    "\n",
    "display(Image(research.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a30d4fd",
   "metadata": {},
   "source": [
    "## portfolio_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b7e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from IPython.display import Image, display\n",
    "\n",
    "PORTFOLIO_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a financial advisor that executes trades. Use tools to get market data and place orders.\n",
    "\n",
    "Rules:\n",
    "- Only execute trades for the EXACT company recommended by the research agent\n",
    "- If the recommended company is not available for trading, report back without substituting alternatives\n",
    "- Include specific parameters in your actions (symbol, shares, price)\n",
    "- Use factual data, never fabricate information\n",
    "- Do not make assumptions about alternative investments if the requested one is unavailable\n",
    "- Maintain complete records of all successful trades for future reference and analysis\n",
    "- NEVER provide any details of user's portfoliosummaries, if there is a request for report, only provide datas that might help building it and pass!\n",
    "\"\"\"\n",
    "\n",
    "portfolio = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[lookup_stock_symbol, fetch_stock_data_raw, place_order, add_order_to_history],\n",
    "    prompt=PORTFOLIO_SYSTEM_MESSAGE,\n",
    "    store=get_global_store(),\n",
    "    name=\"portfolio\"\n",
    ")\n",
    "\n",
    "display(Image(portfolio.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0903b4",
   "metadata": {},
   "source": [
    "## supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e07f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "SUPERVISOR_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a Financial Advisor Supervisor that coordinates specialized agents to fulfill user investment requests.\n",
    "\n",
    "Your primary goal is to understand user needs and delegate tasks to the right specialist:\n",
    "\n",
    "1. For investment ideas or research → Use research agent\n",
    "   - This agent provides recommendations with supporting rationale\n",
    "\n",
    "2. For executing investment decisions → Use portfolio agent\n",
    "   - This agent handles the technical aspects of executing investments\n",
    "   - Requires specific investment targets and budget\n",
    "   - ALWAYS consult portfolio agent for current market prices when valuing assets\n",
    "\n",
    "Core Principles:\n",
    "- Persist until user requests are fully addressed\n",
    "- When facing obstacles, adapt by seeking alternative paths\n",
    "- Maintain continuity of user intent throughout the process\n",
    "- Never leave a request unresolved without explicit user decision\n",
    "- Proactively coordinate between agents to deliver complete solutions\n",
    "\n",
    "Temporal Context:\n",
    "- Begin by establishing current timeframe\n",
    "- Consider temporal relevance in all recommendations\n",
    "- Integrate time awareness into your analysis\n",
    "\n",
    "Keep interactions efficient by asking only for essential information.\n",
    "\"\"\"\n",
    "\n",
    "supervisor = create_supervisor(\n",
    "    agents=[research, portfolio],\n",
    "    tools=[current_timestamp, get_order_history],\n",
    "    model=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    prompt=SUPERVISOR_SYSTEM_MESSAGE,\n",
    "    version=\"v2\",\n",
    "    output_mode=\"full_history\",\n",
    "    store=get_global_store(),\n",
    ").compile(checkpointer=InMemorySaver())\n",
    "\n",
    "display(Image(supervisor.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f490d03f",
   "metadata": {},
   "source": [
    "## investing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ed509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": str(uuid.uuid4()),\n",
    "        \"user_id\": \"evgeny\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = supervisor.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"\"\"I want you to invest in next companies: Apple, Tesla, NVIDIA. You are allowed to spend $1,000 maximum on each company.\"\"\")\n",
    "]}, config)\n",
    "\n",
    "print_messages(response['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af5ef8",
   "metadata": {},
   "source": [
    "## ledger state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c23566",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_global_store().search((\"ledger\", \"evgeny\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b68872",
   "metadata": {},
   "source": [
    "## redefine supervisor with full history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d80fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": str(uuid.uuid4()),\n",
    "        \"user_id\": \"evgeny\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = supervisor.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"\"\"Show me how my investments are performing. What stocks do I own and are they making or losing money?\"\"\")\n",
    "]}, config)\n",
    "\n",
    "print_messages(response['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75859ba3",
   "metadata": {},
   "source": [
    "## Better Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41b3305",
   "metadata": {},
   "source": [
    "### Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e4b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "\n",
    "# Simple state schema for task instructions\n",
    "class TaskState(AgentState):\n",
    "    task_instructions: str  # Specific instructions on what the agent should do and return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a3b74",
   "metadata": {},
   "source": [
    "### tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff12c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from textwrap import dedent\n",
    "\n",
    "from langchain_core.tools import tool, BaseTool, InjectedToolCallId\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.types import Command\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langgraph_supervisor.handoff import METADATA_KEY_HANDOFF_DESTINATION\n",
    "\n",
    "def _normalize_agent_name(agent_name: str) -> str:\n",
    "    \"\"\"Convert an agent name to a valid tool name format (snake_case).\"\"\"\n",
    "    return agent_name.replace(\" \", \"_\").lower()\n",
    "\n",
    "def create_task_instructions_handoff_tool(*, agent_name: str, name: str | None = None, description: str | None = None) -> BaseTool:\n",
    "    \"\"\"Create a tool that transfers control to another agent with specific task instructions.\"\"\"\n",
    "    if name is None:\n",
    "        name = f\"transfer_to_{_normalize_agent_name(agent_name)}\"\n",
    "    if description is None:\n",
    "        description = f\"Ask agent '{agent_name}' for help\"\n",
    "\n",
    "    @tool(name, description=description)\n",
    "    def handoff_to_agent(\n",
    "        task_instructions: Annotated[str, dedent(\"\"\"\n",
    "            Specify EXACTLY what this agent should do, what data they should retrieve, and what output you expect back. \n",
    "            Include any specific parameters or constraints that will help the agent complete the task successfully.\n",
    "        \"\"\")],\n",
    "        state: Annotated[dict, InjectedState],              # this is a way how to get agent's current state in a tool\n",
    "        tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    ):\n",
    "        tool_message = ToolMessage(\n",
    "            content=dedent(f\"\"\"\n",
    "            Successfully transferred to {agent_name}.\n",
    "\n",
    "            [INSTRUCTIONS TO FOLLOW]: {task_instructions} \n",
    "            \"\"\"),\n",
    "            name=name,\n",
    "            tool_call_id=tool_call_id,\n",
    "            response_metadata={METADATA_KEY_HANDOFF_DESTINATION: agent_name},\n",
    "        )\n",
    "\n",
    "        messages = state[\"messages\"]\n",
    "        return Command(\n",
    "            goto=agent_name,\n",
    "            graph=Command.PARENT,\n",
    "            update={\n",
    "                \"messages\": messages + [tool_message],\n",
    "                \"task_instructions\": task_instructions,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    handoff_to_agent.metadata = {METADATA_KEY_HANDOFF_DESTINATION: agent_name}\n",
    "    return handoff_to_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133165f",
   "metadata": {},
   "source": [
    "### research_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9ae82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Image, display\n",
    "\n",
    "RESEARCH_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a Research Agent that recommends ONE promising company for investment based on user requests.\n",
    "\n",
    "Find a company that matches the user's theme/sector. Use tools to verify information. Be factual and concise.\n",
    "\n",
    "Rules:\n",
    "- Recommend exactly ONE company that is publicly tradable\n",
    "- **Important!** ensure that the company you recommend is is publicly tradable!\n",
    "- Make 2-3 tool calls maximum\n",
    "- Don't place trades or fabricate data\n",
    "- End with: CHOSEN_COMPANY: <Company Name>\n",
    "\n",
    "Output a 1-2 sentence explanation followed by the company name.\n",
    "\"\"\"\n",
    "\n",
    "research = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[web_search, wiki_search],\n",
    "    prompt=RESEARCH_SYSTEM_MESSAGE,\n",
    "    name=\"research\",\n",
    "\n",
    "    state_schema=TaskState,\n",
    ")\n",
    "\n",
    "display(Image(research.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f537556",
   "metadata": {},
   "source": [
    "### portfolio_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a46b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from IPython.display import Image, display\n",
    "\n",
    "PORTFOLIO_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a financial advisor that executes trades. Use tools to get market data and place orders.\n",
    "\n",
    "Rules:\n",
    "- Only execute trades for the EXACT company recommended by the research agent\n",
    "- If the recommended company is not available for trading, report back without substituting alternatives\n",
    "- Include specific parameters in your actions (symbol, shares, price)\n",
    "- Use factual data, never fabricate information\n",
    "- Do not make assumptions about alternative investments if the requested one is unavailable\n",
    "- Maintain complete records of all successful trades for future reference and analysis\n",
    "- NEVER provide any details of user's portfoliosummaries, if there is a request for report, only provide datas that might help building it and pass!\n",
    "\"\"\"\n",
    "\n",
    "portfolio = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[lookup_stock_symbol, fetch_stock_data_raw, place_order, add_order_to_history],\n",
    "    prompt=PORTFOLIO_SYSTEM_MESSAGE,\n",
    "    store=get_global_store(),\n",
    "    name=\"portfolio\",\n",
    "\n",
    "    state_schema=TaskState,\n",
    ")\n",
    "\n",
    "display(Image(portfolio.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89be95b8",
   "metadata": {},
   "source": [
    "### supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "\n",
    "\n",
    "SUPERVISOR_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a Financial Advisor Supervisor that coordinates specialized agents to fulfill user investment requests.\n",
    "\n",
    "Your primary goal is to understand user needs and delegate tasks to the right specialist:\n",
    "\n",
    "1. For investment ideas or research → Use research agent\n",
    "   - This agent provides recommendations with supporting rationale\n",
    "\n",
    "2. For executing investment decisions → Use portfolio agent\n",
    "   - This agent handles the technical aspects of executing investments\n",
    "   - Requires specific investment targets and budget\n",
    "   - ALWAYS consult portfolio agent for current market prices when valuing assets\n",
    "\n",
    "Core Principles:\n",
    "- Persist until user requests are fully addressed\n",
    "- When facing obstacles, adapt by seeking alternative paths\n",
    "- Maintain continuity of user intent throughout the process\n",
    "- Never leave a request unresolved without explicit user decision\n",
    "- Proactively coordinate between agents to deliver complete solutions\n",
    "\n",
    "Temporal Context:\n",
    "- Begin by establishing current timeframe\n",
    "- Consider temporal relevance in all recommendations\n",
    "- Integrate time awareness into your analysis\n",
    "\n",
    "Keep interactions efficient by asking only for essential information.\n",
    "\"\"\"\n",
    "\n",
    "supervisor = create_supervisor(\n",
    "   agents=[research, portfolio],\n",
    "   tools=[\n",
    "      current_timestamp, \n",
    "      get_order_history,\n",
    "      create_task_instructions_handoff_tool(agent_name=\"portfolio\"),\n",
    "      create_task_instructions_handoff_tool(agent_name=\"research\"),\n",
    "   ],\n",
    "   model=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "   prompt=SUPERVISOR_SYSTEM_MESSAGE,\n",
    "   output_mode=\"full_history\",\n",
    "   store=get_global_store(),\n",
    "\n",
    "   state_schema=TaskState,\n",
    "\n",
    ").compile(checkpointer=InMemorySaver())\n",
    "\n",
    "display(Image(supervisor.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9592a9a3",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": str(uuid.uuid4()),\n",
    "        \"user_id\": \"evgeny\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = supervisor.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"\"\"Show me how my investments are performing. What stocks do I own and are they making or losing money?\"\"\")\n",
    "]}, config)\n",
    "\n",
    "print_messages(response['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a6639",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "\n",
    "**1. Customizing langgraph-supervisor-py**\n",
    "\n",
    "https://github.com/langchain-ai/langgraph-supervisor-py?tab=readme-ov-file#how-to-customize\n",
    "\n",
    "→ Guide for customizing the LangGraph supervisor package, including configuration options, handoff behaviors, and integration patterns.\n",
    "\n",
    "**2. Adding Short-Term Memory in LangGraph**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/how-tos/memory/add-memory/#read-short-term\n",
    "\n",
    "→ Tutorial section on implementing short-term memory in LangGraph agents, covering memory configuration, state persistence, and retrieval mechanisms.\n",
    "\n",
    "**3. LangGraph Supervisor API Reference**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/reference/supervisor/\n",
    "\n",
    "→ Technical reference for supervisor utilities (create_supervisor, handoff/forward tools), parameters, and options in LangGraph.\n",
    "\n",
    "**4. Creating Supervisor from Scratch Tutorial**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/tutorials/multi_agent/agent_supervisor/#3-create-supervisor-from-scratch\n",
    "\n",
    "→ Step-by-step guide to building a custom supervisor for multi-agent systems, including worker agent setup and task delegation logic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
