{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44d4aa3",
   "metadata": {},
   "source": [
    "# MCP Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ca172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph_mermaid import MermaidDrawMethod\n",
    "\n",
    "def draw_mermaid_png(agent):\n",
    "    nest_asyncio.apply()\n",
    "    display(Image(agent.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.PYPPETEER)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebbeaef",
   "metadata": {},
   "source": [
    "## Single Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536199ff",
   "metadata": {},
   "source": [
    "### Load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def load_mcp_servers(config_path):\n",
    "    \"\"\"\n",
    "    Load MCP server definitions from a JSON config file.\n",
    "    Expects a top-level 'mcpServers' dict in the config.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(config_path):\n",
    "        raise FileNotFoundError(f\"Config file not found: {config_path}\")\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "    servers = config.get(\"mcpServers\", {})\n",
    "    # Optionally add default transports if missing\n",
    "    for name, server in servers.items():\n",
    "        if \"command\" in server and \"transport\" not in server:\n",
    "            server[\"transport\"] = \"stdio\"\n",
    "        if \"url\" in server and \"transport\" not in server:\n",
    "            server[\"transport\"] = \"streamable_http\"\n",
    "    return servers\n",
    "\n",
    "mcp_servers = load_mcp_servers(\"./mcp_config.json\")\n",
    "mcp_servers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0478d9",
   "metadata": {},
   "source": [
    "### Define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd56d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "client = MultiServerMCPClient(mcp_servers)\n",
    "mcp_tools = await client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c66fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mcp_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee7e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_tools[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d649d",
   "metadata": {},
   "source": [
    "### ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12408efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from IPython.display import Image, display\n",
    "\n",
    "GITHUB_AGENT_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a GitHub Assistant that helps users manage their GitHub repositories and workflows.\n",
    "\n",
    "You can help with:\n",
    "- Repository management (create, fork, browse files)\n",
    "- Issues and pull requests (create, review, merge)\n",
    "- Code operations (search, commit, push changes)\n",
    "- GitHub Actions workflows (run, monitor, debug)\n",
    "- Notifications and alerts\n",
    "\n",
    "Use the appropriate GitHub tools based on user requests. \n",
    "For complex tasks, break them down into steps and explain what you're doing along the way.\n",
    "\n",
    "When a user needs help with GitHub, they should simply describe what they want to accomplish, \n",
    "and you'll guide them through the process using the available tools.\n",
    "\"\"\"\n",
    "\n",
    "github_agent = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=mcp_tools,\n",
    "    prompt=GITHUB_AGENT_SYSTEM_MESSAGE\n",
    ")\n",
    "\n",
    "draw_mermaid_png(github_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908d1a8d",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from textwrap import dedent\n",
    "\n",
    "prompt = dedent(\"\"\"\n",
    "Can you check my account on GitHub and look at my recent work on the langgraph-advanced repo? \n",
    "I want to understand what I've been working on lately.\n",
    "So collect information about all my recent activity and provide a brief overview in natural human language \n",
    "about my recent work.\n",
    "\"\"\")\n",
    "\n",
    "messages = await github_agent.ainvoke({\"messages\": [HumanMessage(content=prompt)]})\n",
    "for message in messages['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec30a88",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bfa984",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mcp_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa32f519",
   "metadata": {},
   "source": [
    "## Supervisor with smaller Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mcp_tools[0].name)\n",
    "print(mcp_tools[0].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6dc5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class AgentDefinition(BaseModel):\n",
    "    name: str = Field(description=\"Descriptive name of the agent\")\n",
    "    responsibility: str = Field(description=\"Clear description of what this agent is responsible for\")\n",
    "    system_message: str = Field(description=\"System message that guides the agent's behavior\")\n",
    "    tools: List[str] = Field(description=\"List of tool names this agent should have access to\")\n",
    "\n",
    "class AgentDefinitions(BaseModel):\n",
    "    agents: List[AgentDefinition] = Field(description=\"List of agent definitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "def _normalize_agent_name(agent_name: str) -> str:\n",
    "    \"\"\"Convert an agent name to a valid tool name format (snake_case).\"\"\"\n",
    "    return agent_name.replace(\" \", \"_\").lower()\n",
    "\n",
    "\n",
    "def create_agent_definitions(tools: list[BaseTool]) -> AgentDefinitions:\n",
    "    # Extract tool information\n",
    "    tool_info = []\n",
    "    for tool in tools:\n",
    "        tool_info.append({\n",
    "            \"name\": tool.name,\n",
    "            \"description\": tool.description\n",
    "        })\n",
    "    \n",
    "    # Create prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in designing multi-agent systems. I have a collection of {len(tool_info)} GitHub-related tools \n",
    "    that I want to organize into logical agent groups.\n",
    "    \n",
    "    Each tool has a name and description. I want you to analyze these tools and group them into 3-4 logical specialized agents based on related functionality and purpose. Focus on creating broader categories that group related functionality together.\n",
    "    \n",
    "    For each agent, provide:\n",
    "    1. A descriptive name\n",
    "    2. A clear responsibility statement\n",
    "    3. A concise system message (2-3 sentences) written in SECOND-PERSON perspective (e.g., \"You manage GitHub issues...\" NOT \"I manage GitHub issues...\")\n",
    "    4. A list of tools this agent should have access to\n",
    "    \n",
    "    The goal is to create specialized agents that each handle a specific domain of GitHub operations,\n",
    "    rather than having one agent with too many tools that might get confused.\n",
    "    \n",
    "    Here are the available tools:\n",
    "    {tool_info}\n",
    "    \n",
    "    Make sure every tool is assigned to exactly one agent, and the groupings are logical based on related functionality.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the LLM to get agent definitions\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    structured_model = model.with_structured_output(AgentDefinitions)\n",
    "    \n",
    "    response = structured_model.invoke(prompt)\n",
    "\n",
    "    # Normalize agent names in the response\n",
    "    for agent in response.agents:\n",
    "        agent.name = _normalize_agent_name(agent.name)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e42a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_definitions = create_agent_definitions(mcp_tools).agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c99674",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agent_definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb2c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_definitions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffceb65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "\n",
    "def create_agents(\n",
    "    agent_definitions: List[AgentDefinition],\n",
    "    tools: list[BaseTool]\n",
    ") -> List[CompiledStateGraph]:\n",
    "    agents = []\n",
    "    for agent_def in agent_definitions:\n",
    "        agent_tools = [tool for tool in tools if tool.name in agent_def.tools]\n",
    "        agent = create_react_agent(\n",
    "            model=\"openai:gpt-4o-mini\",\n",
    "            tools=agent_tools,\n",
    "            prompt=agent_def.system_message,\n",
    "            name=agent_def.name\n",
    "        )\n",
    "        print(agent_def.name)\n",
    "        print(agent_def.system_message)\n",
    "        print(agent_def.tools)\n",
    "        print(\"-\"*40)\n",
    "        agents.append(agent)\n",
    "    return agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3127e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = create_agents(agent_definitions, mcp_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce797114",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_mermaid_png(agents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86a2b43",
   "metadata": {},
   "source": [
    "### Supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc26e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from datetime import datetime\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# Generate the agent names and responsibilities section\n",
    "agents_info = \"\\n\".join([f\"- {agent.name.lower()}: {agent.responsibility}\" for agent in agent_definitions])\n",
    "\n",
    "supervisor_system_message = f\"\"\"\n",
    "You are a GitHub Assistant Supervisor that coordinates specialized agents to help users with GitHub tasks.\n",
    "\n",
    "Your agents:\n",
    "{agents_info}\n",
    "\n",
    "Your responsibilities:\n",
    "1. Understand the user's request and determine which agent can best handle it\n",
    "2. Route the request to the appropriate agent based on the task type\n",
    "3. Present the agent's response back to the user\n",
    "4. If a task requires multiple agents, coordinate the handoff between them\n",
    "\n",
    "When routing:\n",
    "- Match the user's request to the most relevant agent's responsibility\n",
    "- If unsure which agent to use, choose the one with the most relevant tools\n",
    "- For complex requests, break them down into subtasks for different agents\n",
    "\n",
    "Keep interactions efficient and focused on solving the user's GitHub tasks.\n",
    "\"\"\"\n",
    "\n",
    "print(supervisor_system_message)\n",
    "\n",
    "supervisor = create_supervisor(\n",
    "    agents=agents,\n",
    "    model=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    prompt=supervisor_system_message,\n",
    "    \n",
    "    output_mode=\"full_history\"\n",
    ").compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_mermaid_png(supervisor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa293f3",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from textwrap import dedent\n",
    "\n",
    "prompt = dedent(\"\"\"\n",
    "Can you check my account on GitHub and look at my recent work on the langgraph-advanced repo? \n",
    "I want to understand what I've been working on lately.\n",
    "So collect information about all my recent activity and provide a brief overview in natural human language \n",
    "about my recent work.\n",
    "\"\"\")\n",
    "\n",
    "messages = await supervisor.ainvoke({\"messages\": [HumanMessage(content=prompt)]})\n",
    "for message in messages['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87432a9a",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "\n",
    "**1. Model Context Protocol (MCP) in LangGraph**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/agents/mcp/\n",
    "\n",
    "→ Guide to integrating Model Context Protocol (MCP) with LangGraph agents, covering MCP server connections, tool exposure, and multi-agent coordination with external context sources.\n",
    "\n",
    "**2. LangChain MCP Adapters: GitHub Repository**\n",
    "\n",
    "https://github.com/langchain-ai/langchain-mcp-adapters\n",
    "\n",
    "→ Official repository for LangChain MCP adapters, providing utilities to connect MCP servers with LangChain/LangGraph agents, including installation, usage examples, and integration patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
