{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "499e4ec5",
   "metadata": {},
   "source": [
    "# Supervisor Multi Agent - Human-In-The-Loop\n",
    "\n",
    "![Supervisor HITL Interrupt/Resume](images/supervisor_hitl_interrupt_resume.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0107c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tool_approval(payload):\n",
    "    tool = payload.get(\"awaiting\", \"unknown_tool\")\n",
    "    args = payload.get(\"args\", {})\n",
    "\n",
    "    print(\"—-- Approval needed —--\")\n",
    "    print(f\"Tool: {tool}\")\n",
    "\n",
    "    if isinstance(args, dict) and args:\n",
    "        print(\"Parameters:\")\n",
    "        for k, v in args.items():\n",
    "            print(f\"  - {k}: {v}\")\n",
    "    elif args:\n",
    "        print(f\"Parameters: {args}\")\n",
    "    else:\n",
    "        print(\"No parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d0e16",
   "metadata": {},
   "source": [
    "### research_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from langchain_core.tools import tool\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "\n",
    "research_system_message = \"\"\"\n",
    "You are a Research Agent specializing in identifying one promising company for potential investment based on the user’s request.\n",
    "\n",
    "Responsibilities:\n",
    "- Interpret the user’s theme or sector (e.g., AI, renewable energy, EVs) and propose ONE company that best fits.\n",
    "- Use the available tools to discover, verify, and cross-check information.\n",
    "- Prefer recent, credible information and avoid speculation.\n",
    "\n",
    "Behavior:\n",
    "- Do NOT place or simulate trades. Your job ends at recommending a company.\n",
    "- Keep research tight (aim for 2–3 tool calls); refine queries if results are noisy.\n",
    "- Ask a brief clarifying question only if the request is too vague to proceed.\n",
    "- Do not fabricate numbers or facts. Be concise, neutral, and risk-aware.\n",
    "- Consider the current date when discussing recency or momentum.\n",
    "\n",
    "Outputs:\n",
    "- 1–2 sentences explaining why the company fits the request (clear, plain language).\n",
    "- Final line: CHOSEN_COMPANY: <Company Name>\n",
    "\"\"\"\n",
    "\n",
    "FORBIDDEN_KEYWORDS = {\n",
    "    \"403 forbidden\", \"access denied\", \"captcha\",\n",
    "    \"has been denied\", \"not authorized\", \"verify you are a human\"\n",
    "}\n",
    "\n",
    "@tool\n",
    "def web_search(query: str, max_results: int = 5) -> Dict[str, List[Dict[str, str]]]:\n",
    "    \"\"\"\n",
    "    General-purpose web search.\n",
    "\n",
    "    Use when you need recent or broader information from the web to answer the user's request\n",
    "    (e.g., discover relevant entities, find supporting context, or gather up-to-date references).\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The search query in plain language.\n",
    "    - max_results (int): Number of results to return (default 5, max 10).\n",
    "\n",
    "    Returns:\n",
    "    - {\"results\": [{\"title\": str, \"url\": str, \"snippet\": str}, ...]}\n",
    "\n",
    "    Example:\n",
    "    - query: \"emerging AI hardware companies\"\n",
    "    \"\"\"\n",
    "    max_results = max(1, min(max_results, 10))\n",
    "    tavily = TavilySearch(max_results=max_results)\n",
    "    raw = tavily.invoke({\"query\": query})\n",
    "\n",
    "    results = [\n",
    "        {k: v for k, v in page.items() if k != \"raw_content\"}  # drop heavy field\n",
    "        for page in raw[\"results\"]\n",
    "        if not any(\n",
    "            k in ((page.get(\"content\") or \"\").lower())\n",
    "            for k in FORBIDDEN_KEYWORDS\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return {\"results\": results}\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "@tool\n",
    "def wiki_search(topic: str, max_results: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Fetch a concise encyclopedic summary for a single entity or topic.\n",
    "\n",
    "    When to use:\n",
    "      - You need neutral background about a company, product, person, or concept.\n",
    "\n",
    "    How to format `topic` (VERY IMPORTANT):\n",
    "      - Pass a short, Wikipedia-friendly title or entity name.\n",
    "      - Avoid questions or long queries. Prefer canonical forms.\n",
    "      - If you have noisy text, reduce it to the key noun phrase.\n",
    "\n",
    "    Good examples:\n",
    "      - \"NVIDIA\", \"OpenAI\", \"Large language model\", \"Electric vehicle\"\n",
    "    Avoid:\n",
    "      - \"What is NVIDIA and why is it important?\", \"tell me about AI chips 2025\"\n",
    "\n",
    "    Parameters:\n",
    "      - topic (str): Canonical page title or concise entity/topic.\n",
    "    \"\"\"\n",
    "    max_results = max(1, min(max_results, 10))\n",
    "    wiki = WikipediaLoader(query=topic, load_max_docs=max_results)\n",
    "    raw = wiki.load()\n",
    "\n",
    "    results = [\n",
    "      {\n",
    "        \"title\": doc.metadata[\"title\"],\n",
    "        \"summary\": doc.metadata[\"summary\"],\n",
    "        \"source\": doc.metadata[\"source\"]\n",
    "      }\n",
    "      for doc in raw\n",
    "    ]\n",
    "\n",
    "    return {\"results\": results}\n",
    "\n",
    "\n",
    "research_agent = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[web_search, wiki_search],\n",
    "    prompt=research_system_message,\n",
    "\n",
    "    name=\"research_agent\"\n",
    ")\n",
    "\n",
    "display(Image(research_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f9e70",
   "metadata": {},
   "source": [
    "### trading_agent with interruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac07ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import yfinance as yf\n",
    "from pprint import pformat\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from IPython.display import Image, display\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "@tool(\"lookup_stock\")\n",
    "def lookup_stock_symbol(company_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a company name to its stock symbol using a financial API.\n",
    "\n",
    "    Parameters:\n",
    "        company_name (str): The full company name (e.g., 'Tesla').\n",
    "\n",
    "    Returns:\n",
    "        str: The stock symbol (e.g., 'TSLA') or an error message.\n",
    "    \"\"\"\n",
    "    api_url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"SYMBOL_SEARCH\",\n",
    "        \"keywords\": company_name,\n",
    "        \"apikey\": \"your_alphavantage_api_key\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"bestMatches\" in data and data[\"bestMatches\"]:\n",
    "        return data[\"bestMatches\"][0][\"1. symbol\"]\n",
    "    else:\n",
    "        return f\"Symbol not found for {company_name}.\"\n",
    "\n",
    "\n",
    "@tool(\"fetch_stock_data\")\n",
    "def fetch_stock_data_raw(stock_symbol: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetches comprehensive stock data for a given symbol and returns it as a combined dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        stock_symbol (str): The stock ticker symbol (e.g., 'TSLA').\n",
    "        period (str): The period to analyze (e.g., '1mo', '3mo', '1y').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary combining general stock info and historical market data.\n",
    "    \"\"\"\n",
    "    period = \"1mo\"\n",
    "    try:\n",
    "        stock = yf.Ticker(stock_symbol)\n",
    "\n",
    "        # Retrieve general stock info and historical market data\n",
    "        stock_info = stock.info  # Basic company and stock data\n",
    "        stock_history = stock.history(period=period).to_dict()  # Historical OHLCV data\n",
    "\n",
    "        # Combine both into a single dictionary\n",
    "        combined_data = {\n",
    "            \"stock_symbol\": stock_symbol,\n",
    "            \"info\": stock_info,\n",
    "            \"history\": stock_history\n",
    "        }\n",
    "\n",
    "        return pformat(combined_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error fetching stock data for {stock_symbol}: {str(e)}\"}\n",
    "\n",
    "trading_system_message = \"\"\"\n",
    "You are a financial advisor assistant. Use the provided tools to ground your answers\n",
    "in up-to-date market data. Be concise, factual, and risk-aware.\n",
    "\n",
    "Be decisive: when you have sufficient information to act, proceed with tool calls without\n",
    "asking for confirmation. Only if information is missing or uncertain, ask a concise \n",
    "clarifying question.\n",
    "\n",
    "When preparing or describing actions, include appropriate parameters (e.g., symbol, shares,\n",
    "limit price, budgets) based on available data. Do not fabricate numbers or facts.\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def place_order(\n",
    "    symbol: str,\n",
    "    action: str,\n",
    "    shares: int,\n",
    "    limit_price: float,\n",
    "    order_type: str = \"limit\",\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Execute a stock order.\n",
    "\n",
    "    Parameters:\n",
    "    - symbol: Ticker\n",
    "    - action: \"buy\" or \"sell\"\n",
    "    - shares: Number of shares to trade (pre-computed by the agent)\n",
    "    - limit_price: Limit price per share\n",
    "    - order_type: Order type, default \"limit\"\n",
    "\n",
    "    Returns:\n",
    "    - status: Execution result (simulated)\n",
    "    - symbol\n",
    "    - shares\n",
    "    - limit_price\n",
    "    - total_spent\n",
    "    - type: Order type used\n",
    "    - action\n",
    "    \"\"\"\n",
    "    total_spent = round(int(shares) * limit_price, 2)\n",
    "    return {\n",
    "        \"status\": \"filled\",\n",
    "        \"symbol\": symbol,\n",
    "        \"shares\": int(shares),\n",
    "        \"limit_price\": limit_price,\n",
    "        \"total_spent\": total_spent,\n",
    "        \"type\": order_type,\n",
    "        \"action\": action,\n",
    "    }\n",
    "\n",
    "\n",
    "RISKY_TOOLS = {\"place_order\"}\n",
    "\n",
    "def halt_on_risky_tools(state):\n",
    "    last = state[\"messages\"][-1]\n",
    "    if isinstance(last, AIMessage) and getattr(last, \"tool_calls\", None):\n",
    "        for tc in last.tool_calls:\n",
    "            if tc.get(\"name\") in RISKY_TOOLS:\n",
    "                decision = interrupt({\"awaiting\": tc[\"name\"], \"args\": tc.get(\"args\", {})})\n",
    "\n",
    "                # tool approved\n",
    "                if isinstance(decision, dict) and decision.get(\"approved\"):\n",
    "                    return {}\n",
    "\n",
    "                # tool rejected\n",
    "                tool_msg = ToolMessage(\n",
    "                    content=f\"Cancelled by human. Continue without executing that tool and provide next steps.\",\n",
    "                    tool_call_id=tc[\"id\"],\n",
    "                    name=tc[\"name\"]\n",
    "                )\n",
    "                return {\"messages\": [tool_msg]}\n",
    "\n",
    "    return {}\n",
    "\n",
    "\n",
    "trading_agent = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[lookup_stock_symbol, fetch_stock_data_raw, place_order],\n",
    "    prompt=trading_system_message,\n",
    "\n",
    "    version=\"v2\",\n",
    "    post_model_hook=halt_on_risky_tools,\n",
    "\n",
    "    name=\"trading_agent\"\n",
    ")\n",
    "\n",
    "display(Image(trading_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f9f0d",
   "metadata": {},
   "source": [
    "### supervisor with checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a31e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from datetime import datetime\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "@tool\n",
    "def current_timestamp() -> dict:\n",
    "    \"\"\"\n",
    "    Return the current local timestamp.\n",
    "\n",
    "    Returns:\n",
    "    - {\"iso\": str, \"epoch\": int, \"tz\": str}\n",
    "      where:\n",
    "      - iso: ISO 8601 string with timezone offset\n",
    "      - epoch: Unix epoch seconds\n",
    "      - tz: timezone name/offset\n",
    "    \"\"\"\n",
    "    now = datetime.now().astimezone()\n",
    "    return {\n",
    "        \"iso\": now.isoformat(),\n",
    "        \"epoch\": int(now.timestamp()),\n",
    "        \"tz\": str(now.tzinfo),\n",
    "    }\n",
    "\n",
    "supervisor_system_message = \"\"\"\n",
    "You are a Supervisor coordinating two specialists:\n",
    "\n",
    "- research_agent: finds ONE suitable company matching the user’s request and explains why.\n",
    "- trading_agent: given a company and a budget/action, determines the ticker, checks market data, sizes the order, and places a trade.\n",
    "\n",
    "Your goal is to satisfy the user’s intent with minimal steps.\n",
    "\n",
    "Clocking / Context:\n",
    "- If the conversation does not already contain a “NOW” context, first obtain it by calling the tool `current_timestamp`.\n",
    "- After obtaining it, post a single one-line note into the thread so it’s available to all subsequent steps, e.g.:\n",
    "  \"System context — NOW: {iso} ({tz}); epoch={epoch}\"\n",
    "- Use this “NOW” as the reference for recency. Do not call `current_timestamp` again unless the prior “NOW” is missing or clearly stale.\n",
    "\n",
    "\n",
    "Routing:\n",
    "- If the request is thematic or ambiguous, ask research_agent.\n",
    "- If the request already names a company and includes an action/budget, use trading_agent.\n",
    "- If a single key detail is missing (e.g., budget), ask once, then proceed.\n",
    "\n",
    "Handoff:\n",
    "- From research_agent expect: one company name + 1–2 sentence rationale.\n",
    "- Pass that company (and any provided budget/action) to trading_agent.\n",
    "\n",
    "Guardrails:\n",
    "- Don’t invent data. Don’t place trades without explicit user budget/action.\n",
    "- Prefer the current date context when judging recency.\n",
    "\n",
    "Output:\n",
    "- Briefly state what you delegated and the result. If blocked, ask only for what’s needed to proceed.\n",
    "\"\"\"\n",
    "\n",
    "supervisor = create_supervisor(\n",
    "    agents=[research_agent, trading_agent],\n",
    "    tools=[current_timestamp],\n",
    "    model=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    prompt=supervisor_system_message,\n",
    "    \n",
    "    output_mode=\"full_history\"\n",
    ").compile(checkpointer=InMemorySaver())\n",
    "\n",
    "display(Image(supervisor.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c0cbb3",
   "metadata": {},
   "source": [
    "### testing positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "response = supervisor.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"\"\"I want you to invest $1,000 into the most promising company in the AI sector.  \n",
    "    Please research the options, pick the best candidate, and then go ahead and place a buy order for me.\n",
    "    \"\"\")\n",
    "]}, config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ecdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"__interrupt__\" in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "interrupts = response[\"__interrupt__\"]\n",
    "print_tool_approval(interrupts[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "response = supervisor.invoke(Command(resume={\"approved\": True}), config=config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaf172b",
   "metadata": {},
   "source": [
    "### testing negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9210ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "response = supervisor.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"\"\"I want you to invest $1,000 into the most promising company in the AI sector.  \n",
    "    Please research the options, pick the best candidate, and then go ahead and place a buy order for me.\n",
    "    \"\"\")\n",
    "]}, config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3040d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"__interrupt__\" in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "interrupts = response[\"__interrupt__\"]\n",
    "print_tool_approval(interrupts[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "response = supervisor.invoke(Command(resume={\"approved\": False}), config=config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72abb0d5",
   "metadata": {},
   "source": [
    "### updating request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a0d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = supervisor.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"\"\"\n",
    "    Let's buy only 3 shares of NVIDIA!\n",
    "    \"\"\")\n",
    "]}, config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc27ba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"__interrupt__\" in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66824098",
   "metadata": {},
   "outputs": [],
   "source": [
    "interrupts = response[\"__interrupt__\"]\n",
    "print_tool_approval(interrupts[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d91c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "response = supervisor.invoke(Command(resume={\"approved\": True}), config=config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8407a5",
   "metadata": {},
   "source": [
    "### new session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5651ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = supervisor.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"\"\"\n",
    "    Can you tell me how much money I still have?\n",
    "    \"\"\")\n",
    "]}, config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = supervisor.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"\"\"\n",
    "    Ok then let's invest the money I still have into another promissing company in the AI sector.\n",
    "    \"\"\")\n",
    "]}, config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd50b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"__interrupt__\" in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e26812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interrupts = response[\"__interrupt__\"]\n",
    "print_tool_approval(interrupts[0].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e79d44",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "\n",
    "**1. LangGraph Graph API: Command + HITL**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/concepts/low_level/\n",
    "\n",
    "→ Overview of core Graph API primitives (Send, Command), Command vs conditional edges, navigating to parent, and HITL with interrupt()/Command(resume=...).\n",
    "\n",
    "**2. Add human intervention (HITL) How‑To**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/add-human-in-the-loop/\n",
    "\n",
    "→ Practical guide to pausing with interrupt() and resuming with Command(resume=...), including common patterns and key considerations.\n",
    "\n",
    "**3. Discussion: Resuming interrupted tool in multi‑agent architecture (#4341)**\n",
    "\n",
    "https://github.com/langchain-ai/langgraph/discussions/4341\n",
    "\n",
    "→ Clarifies that with a parent-owned checkpointer, child interrupts bubble to the parent and resumption must be invoked on the parent (same thread_id)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
