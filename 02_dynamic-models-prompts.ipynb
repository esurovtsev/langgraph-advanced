{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5ce3de",
   "metadata": {},
   "source": [
    "# Prebuilt ReAct Agent - Dynamic Models & Prompt Customization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c570d58b",
   "metadata": {},
   "source": [
    "## Define tools explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def505aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import yfinance as yf\n",
    "from pprint import pformat\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(\"lookup_stock\")\n",
    "def lookup_stock_symbol(company_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a company name to its stock symbol using a financial API.\n",
    "\n",
    "    Parameters:\n",
    "        company_name (str): The full company name (e.g., 'Tesla').\n",
    "\n",
    "    Returns:\n",
    "        str: The stock symbol (e.g., 'TSLA') or an error message.\n",
    "    \"\"\"\n",
    "    api_url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"SYMBOL_SEARCH\",\n",
    "        \"keywords\": company_name,\n",
    "        \"apikey\": \"your_alphavantage_api_key\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"bestMatches\" in data and data[\"bestMatches\"]:\n",
    "        return data[\"bestMatches\"][0][\"1. symbol\"]\n",
    "    else:\n",
    "        return f\"Symbol not found for {company_name}.\"\n",
    "\n",
    "\n",
    "@tool(\"fetch_stock_data\")\n",
    "def fetch_stock_data_raw(stock_symbol: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetches comprehensive stock data for a given symbol and returns it as a combined dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        stock_symbol (str): The stock ticker symbol (e.g., 'TSLA').\n",
    "        period (str): The period to analyze (e.g., '1mo', '3mo', '1y').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary combining general stock info and historical market data.\n",
    "    \"\"\"\n",
    "    period = \"1mo\"\n",
    "    try:\n",
    "        stock = yf.Ticker(stock_symbol)\n",
    "\n",
    "        # Retrieve general stock info and historical market data\n",
    "        stock_info = stock.info  # Basic company and stock data\n",
    "        stock_history = stock.history(period=period).to_dict()  # Historical OHLCV data\n",
    "\n",
    "        # Combine both into a single dictionary\n",
    "        combined_data = {\n",
    "            \"stock_symbol\": stock_symbol,\n",
    "            \"info\": stock_info,\n",
    "            \"history\": stock_history\n",
    "        }\n",
    "\n",
    "        return pformat(combined_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error fetching stock data for {stock_symbol}: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a49834f",
   "metadata": {},
   "source": [
    "## Define the basic agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad15deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import Image, display\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    tools=[lookup_stock_symbol, fetch_stock_data_raw],\n",
    "    prompt=\"You are a helpful assistant. Answer clearly and simply.\"\n",
    ")\n",
    "\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820001e0",
   "metadata": {},
   "source": [
    "## Dynamic Model Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langgraph.runtime import Runtime\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "tools = [lookup_stock_symbol, fetch_stock_data_raw]\n",
    "\n",
    "\n",
    "def dynamic_model_selector(state: AgentState, runtime: Runtime):\n",
    "    \"\"\"Select model depending on the query intent.\"\"\"\n",
    "    model = None\n",
    "\n",
    "    user_msg = state[\"messages\"][-1].content.lower()\n",
    "    if any(word in user_msg for word in [\"analyze\", \"invest\", \"risks\"]):\n",
    "        print(\"Select Model for Heavy reasoning → more powerful model (gpt-4)\")\n",
    "        model=ChatOpenAI(model=\"gpt-4\")\n",
    "    elif \"summarize\" in user_msg:\n",
    "        print(\"Select Model for Quick summarization → lightweight model (gpt-4o-mini)\")\n",
    "        model=ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    else:\n",
    "        print(\"Select Model for Default fallback (gpt-3.5-turbo)\")\n",
    "        model=ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "    \n",
    "    return model.bind_tools(tools)\n",
    "\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=dynamic_model_selector,\n",
    "    tools=tools,\n",
    "    prompt=\"You are a helpful assistant. Answer clearly and simply.\",\n",
    "    checkpointer=InMemorySaver()\n",
    ")\n",
    "\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e0bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "messages = agent.invoke({\"messages\": [HumanMessage(content=\"Hi!\")]}, config)\n",
    "for message in messages['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560db387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = agent.invoke({\"messages\": [HumanMessage(content=\"summarize what HITL is\")]}, config)\n",
    "for message in messages['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730b375",
   "metadata": {},
   "source": [
    "## Dynamic Prompt Modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "def prompt_modifier(state):\n",
    "    \"\"\"Change the agent's behavior depending on the query intent.\"\"\"\n",
    "    user_msg = state[\"messages\"][-1].content.lower()\n",
    "\n",
    "    if \"invest\" in user_msg or \"risks\" in user_msg:\n",
    "        prompt=\"You are a financial advisor. Give clear analysis of risks and opportunities.\"\n",
    "    elif \"summarize\" in user_msg:\n",
    "        prompt=\"You are a summarizer. Keep the answer short and clear.\"\n",
    "    elif \"explain\" in user_msg:\n",
    "        prompt=\"You are a teacher. Explain concepts step by step in simple terms.\"\n",
    "    else:\n",
    "        prompt=\"You are a helpful assistant. Answer clearly and simply.\"\n",
    "    \n",
    "    print(f\"Selected prompt: {prompt}\")\n",
    "\n",
    "    # Filter out any existing system messages\n",
    "    non_system_messages = [msg for msg in state[\"messages\"] if msg.type != \"system\"]\n",
    "\n",
    "    # Return the new system message + all non-system messages\n",
    "    return [SystemMessage(content=prompt)] + non_system_messages\n",
    "\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    tools=[lookup_stock_symbol, fetch_stock_data_raw],\n",
    "    prompt=prompt_modifier,\n",
    "    checkpointer=InMemorySaver()\n",
    ")\n",
    "\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c857e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "messages = agent.invoke({\"messages\": [HumanMessage(content=\"Hi!\")]}, config)\n",
    "for message in messages['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f1e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = agent.invoke({\"messages\": [HumanMessage(content=\"summarize what HITL is\")]}, config)\n",
    "for message in messages['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396d03a",
   "metadata": {},
   "source": [
    "## Combining All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bfd38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langgraph.runtime import Runtime\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "\n",
    "tools = [lookup_stock_symbol, fetch_stock_data_raw]\n",
    "\n",
    "\n",
    "def dynamic_model_selector(state: AgentState, runtime: Runtime):\n",
    "    \"\"\"Select model depending on the query intent.\"\"\"\n",
    "    model = None\n",
    "\n",
    "    user_msg = state[\"messages\"][-1].content.lower()\n",
    "    if any(word in user_msg for word in [\"analyze\", \"invest\", \"risks\"]):\n",
    "        print(\"Select Model for Heavy reasoning → more powerful model (gpt-4-turbo)\")\n",
    "        model=ChatOpenAI(model=\"gpt-4-turbo\")\n",
    "    elif \"summarize\" in user_msg:\n",
    "        print(\"Select Model for Quick summarization → lightweight model (gpt-4o-mini)\")\n",
    "        model=ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    else:\n",
    "        print(\"Select Model for Default fallback (gpt-3.5-turbo)\")\n",
    "        model=ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "    \n",
    "    return model.bind_tools(tools)\n",
    "\n",
    "\n",
    "def prompt_modifier(state):\n",
    "    \"\"\"Change the agent's behavior depending on the query intent.\"\"\"\n",
    "    user_msg = state[\"messages\"][-1].content.lower()\n",
    "\n",
    "    if \"invest\" in user_msg or \"risks\" in user_msg:\n",
    "        prompt=\"You are a financial advisor. Give clear analysis of risks and opportunities.\"\n",
    "    elif \"summarize\" in user_msg:\n",
    "        prompt=\"You are a summarizer. Keep the answer short and clear.\"\n",
    "    elif \"explain\" in user_msg:\n",
    "        prompt=\"You are a teacher. Explain concepts step by step in simple terms.\"\n",
    "    else:\n",
    "        prompt=\"You are a helpful assistant. Answer clearly and simply.\"\n",
    "    \n",
    "    print(f\"Selected prompt: {prompt}\")\n",
    "\n",
    "    # Filter out any existing system messages\n",
    "    non_system_messages = [msg for msg in state[\"messages\"] if msg.type != \"system\"]\n",
    "\n",
    "    # Return the new system message + all non-system messages\n",
    "    return [SystemMessage(content=prompt)] + non_system_messages\n",
    "\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=dynamic_model_selector,\n",
    "    tools=tools,\n",
    "    prompt=prompt_modifier,\n",
    "    checkpointer=InMemorySaver()\n",
    ")\n",
    "\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0179f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "messages = agent.invoke({\"messages\": [HumanMessage(content=\"What’s Tesla’s stock symbol?\")]}, config)\n",
    "for message in messages['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df5ad65",
   "metadata": {},
   "source": [
    "From the debug messages you can see that both `dynamic_model_selector` and `prompt_modifier` were triggered twice — once per node. This means you can adjust the model and prompt separately at each node, rather than only once for the whole graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4668bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = agent.invoke({\"messages\": [HumanMessage(content=\"Summarize Tesla’s financials.\")]}, config)\n",
    "for message in messages['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6489b3a6",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "\n",
    "**LangGraph Prebuilt ReAct Agent (create_react_agent)**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.chat_agent_executor.create_react_agent\n",
    "\n",
    "→ API reference for the create_react_agent function. This function builds a ready-to-use ReAct agent graph from a language model, tool list, and optional configuration. It supports static or dynamic model selection, prompt customization, memory, hooks, human‑in‑the‑loop, and other advanced features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
