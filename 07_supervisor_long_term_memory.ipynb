{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17fb6b6e",
   "metadata": {},
   "source": [
    "# Supervisor Multi Agent - Long Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5862c8",
   "metadata": {},
   "source": [
    "## tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1611ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_tavily import TavilySearch\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from pprint import pformat\n",
    "from datetime import datetime\n",
    "\n",
    "FORBIDDEN_KEYWORDS = {\n",
    "    \"403 forbidden\", \"access denied\", \"captcha\",\n",
    "    \"has been denied\", \"not authorized\", \"verify you are a human\"\n",
    "}\n",
    "\n",
    "@tool\n",
    "def web_search(query: str, max_results: int = 5) -> Dict[str, List[Dict[str, str]]]:\n",
    "    \"\"\"\n",
    "    General-purpose web search.\n",
    "\n",
    "    Use when you need recent or broader information from the web to answer the user's request\n",
    "    (e.g., discover relevant entities, find supporting context, or gather up-to-date references).\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The search query in plain language.\n",
    "    - max_results (int): Number of results to return (default 5, max 10).\n",
    "\n",
    "    Returns:\n",
    "    - {\"results\": [{\"title\": str, \"url\": str, \"snippet\": str}, ...]}\n",
    "\n",
    "    Example:\n",
    "    - query: \"emerging AI hardware companies\"\n",
    "    \"\"\"\n",
    "    max_results = max(1, min(max_results, 10))\n",
    "    tavily = TavilySearch(max_results=max_results)\n",
    "    raw = tavily.invoke({\"query\": query})\n",
    "\n",
    "    results = [\n",
    "        {k: v for k, v in page.items() if k != \"raw_content\"}  # drop heavy field\n",
    "        for page in raw[\"results\"]\n",
    "        if not any(\n",
    "            k in ((page.get(\"content\") or \"\").lower())\n",
    "            for k in FORBIDDEN_KEYWORDS\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return {\"results\": results}\n",
    "\n",
    "\n",
    "@tool\n",
    "def wiki_search(topic: str, max_results: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Fetch a concise encyclopedic summary for a single entity or topic.\n",
    "\n",
    "    When to use:\n",
    "      - You need neutral background about a company, product, person, or concept.\n",
    "\n",
    "    How to format `topic` (VERY IMPORTANT):\n",
    "      - Pass a short, Wikipedia-friendly title or entity name.\n",
    "      - Avoid questions or long queries. Prefer canonical forms.\n",
    "      - If you have noisy text, reduce it to the key noun phrase.\n",
    "\n",
    "    Good examples:\n",
    "      - \"NVIDIA\", \"OpenAI\", \"Large language model\", \"Electric vehicle\"\n",
    "    Avoid:\n",
    "      - \"What is NVIDIA and why is it important?\", \"tell me about AI chips 2025\"\n",
    "\n",
    "    Parameters:\n",
    "      - topic (str): Canonical page title or concise entity/topic.\n",
    "    \"\"\"\n",
    "    max_results = max(1, min(max_results, 10))\n",
    "    wiki = WikipediaLoader(query=topic, load_max_docs=max_results)\n",
    "    raw = wiki.load()\n",
    "\n",
    "    results = [\n",
    "      {\n",
    "        \"title\": doc.metadata[\"title\"],\n",
    "        \"summary\": doc.metadata[\"summary\"],\n",
    "        \"source\": doc.metadata[\"source\"]\n",
    "      }\n",
    "      for doc in raw\n",
    "    ]\n",
    "\n",
    "    return {\"results\": results}\n",
    "\n",
    "\n",
    "@tool(\"lookup_stock\")\n",
    "def lookup_stock_symbol(company_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a company name to its stock symbol using a financial API.\n",
    "\n",
    "    Parameters:\n",
    "        company_name (str): The full company name (e.g., 'Tesla').\n",
    "\n",
    "    Returns:\n",
    "        str: The stock symbol (e.g., 'TSLA') or an error message.\n",
    "    \"\"\"\n",
    "    api_url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"SYMBOL_SEARCH\",\n",
    "        \"keywords\": company_name,\n",
    "        \"apikey\": \"your_alphavantage_api_key\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"bestMatches\" in data and data[\"bestMatches\"]:\n",
    "        return data[\"bestMatches\"][0][\"1. symbol\"]\n",
    "    else:\n",
    "        return f\"Symbol not found for {company_name}.\"\n",
    "\n",
    "\n",
    "@tool(\"fetch_stock_data\")\n",
    "def fetch_stock_data_raw(stock_symbol: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetches comprehensive stock data for a given symbol and returns it as a combined dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        stock_symbol (str): The stock ticker symbol (e.g., 'TSLA').\n",
    "        period (str): The period to analyze (e.g., '1mo', '3mo', '1y').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary combining general stock info and historical market data.\n",
    "    \"\"\"\n",
    "    period = \"1mo\"\n",
    "    try:\n",
    "        stock = yf.Ticker(stock_symbol)\n",
    "\n",
    "        # Retrieve general stock info and historical market data\n",
    "        stock_info = stock.info  # Basic company and stock data\n",
    "        stock_history = stock.history(period=period).to_dict()  # Historical OHLCV data\n",
    "\n",
    "        # Combine both into a single dictionary\n",
    "        combined_data = {\n",
    "            \"stock_symbol\": stock_symbol,\n",
    "            \"info\": stock_info,\n",
    "            \"history\": stock_history\n",
    "        }\n",
    "\n",
    "        return pformat(combined_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error fetching stock data for {stock_symbol}: {str(e)}\"}\n",
    "\n",
    "\n",
    "@tool\n",
    "def place_order(\n",
    "    symbol: str,\n",
    "    action: str,\n",
    "    shares: int,\n",
    "    limit_price: float,\n",
    "    order_type: str = \"limit\",\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Execute a stock order.\n",
    "\n",
    "    Parameters:\n",
    "    - symbol: Ticker\n",
    "    - action: \"buy\" or \"sell\"\n",
    "    - shares: Number of shares to trade (pre-computed by the agent)\n",
    "    - limit_price: Limit price per share\n",
    "    - order_type: Order type, default \"limit\"\n",
    "\n",
    "    Returns:\n",
    "    - status: Execution result (simulated)\n",
    "    - symbol\n",
    "    - shares\n",
    "    - limit_price\n",
    "    - total_spent\n",
    "    - type: Order type used\n",
    "    - action\n",
    "    \"\"\"\n",
    "    total_spent = round(int(shares) * limit_price, 2)\n",
    "    return {\n",
    "        \"status\": \"filled\",\n",
    "        \"symbol\": symbol,\n",
    "        \"shares\": int(shares),\n",
    "        \"limit_price\": limit_price,\n",
    "        \"total_spent\": total_spent,\n",
    "        \"type\": order_type,\n",
    "        \"action\": action,\n",
    "    }\n",
    "\n",
    "\n",
    "@tool\n",
    "def current_timestamp() -> dict:\n",
    "    \"\"\"\n",
    "    Return the current local timestamp.\n",
    "\n",
    "    Returns:\n",
    "    - {\"iso\": str, \"epoch\": int, \"tz\": str}\n",
    "      where:\n",
    "      - iso: ISO 8601 string with timezone offset\n",
    "      - epoch: Unix epoch seconds\n",
    "      - tz: timezone name/offset\n",
    "    \"\"\"\n",
    "    now = datetime.now().astimezone()\n",
    "    return {\n",
    "        \"iso\": now.isoformat(),\n",
    "        \"epoch\": int(now.timestamp()),\n",
    "        \"tz\": str(now.tzinfo),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ef774e",
   "metadata": {},
   "source": [
    "## research_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f81480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Image, display\n",
    "\n",
    "RESEARCH_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a Research Agent that recommends ONE promising company for investment based on user requests.\n",
    "\n",
    "Find a company that matches the user's theme/sector. Use tools to verify information. Be factual and concise.\n",
    "\n",
    "Rules:\n",
    "- Recommend exactly ONE company that is publicly tradable\n",
    "- **Important!** ensure that the company you recommend is is publicly tradable!\n",
    "- Make 2-3 tool calls maximum\n",
    "- Don't place trades or fabricate data\n",
    "- End with: CHOSEN_COMPANY: <Company Name>\n",
    "\n",
    "Output a 1-2 sentence explanation followed by the company name.\n",
    "\"\"\"\n",
    "\n",
    "research = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[web_search, wiki_search],\n",
    "    prompt=RESEARCH_SYSTEM_MESSAGE,\n",
    "\n",
    "    name=\"research\"\n",
    ")\n",
    "\n",
    "display(Image(research.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19014350",
   "metadata": {},
   "source": [
    "## Memory Tools & Store Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb653dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.config import get_store\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "import uuid\n",
    "\n",
    "_GLOBAL_STORE = None\n",
    "\n",
    "def initialize_store(store):\n",
    "    global _GLOBAL_STORE\n",
    "    _GLOBAL_STORE = store\n",
    "\n",
    "def get_global_store():\n",
    "    return _GLOBAL_STORE\n",
    "\n",
    "initialize_store(InMemoryStore())\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_order_history(config: RunnableConfig) -> list:\n",
    "    \"\"\"\n",
    "    Retrieves past investment orders for the current user.\n",
    "    \n",
    "    Returns:\n",
    "        A list of past orders with details including order_id, timestamp, symbol, shares, and price\n",
    "        \n",
    "    Example Usage: \n",
    "        Review previous investments before recommending new ones\n",
    "    \"\"\"\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    namespace = (\"ledger\", user_id)\n",
    "    store = get_global_store()\n",
    "    items = store.search(namespace)\n",
    "    return [item.value for item in items]\n",
    "    \n",
    "\n",
    "@tool\n",
    "def add_order_to_history(symbol: str, shares: int, price: float, config: RunnableConfig) -> dict:\n",
    "    \"\"\"\n",
    "    Records a new investment order in the user's order history.\n",
    "    \n",
    "    Args:\n",
    "        symbol: Stock ticker symbol (e.g., 'AAPL', 'MSFT')\n",
    "        shares: Number of shares purchased or sold (positive for buy, negative for sell)\n",
    "        price: Price per share in USD\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the newly created order details including order_id and timestamp\n",
    "        \n",
    "    Example:\n",
    "        To record a purchase of 10 shares of Apple at $190.50:\n",
    "        add_order_to_history(symbol='AAPL', shares=10, price=190.50)\n",
    "    \"\"\"\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    namespace = (\"ledger\", user_id)\n",
    "    store = get_global_store()\n",
    "\n",
    "    order_id = str(uuid.uuid4())\n",
    "    order = {\n",
    "        \"order_id\": order_id,\n",
    "        \"ts\": datetime.now().isoformat(),\n",
    "        \"symbol\": symbol,\n",
    "        \"shares\": shares,\n",
    "        \"price\": price\n",
    "    }\n",
    "    store.put(namespace, order_id, order)\n",
    "\n",
    "    return order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb93aa",
   "metadata": {},
   "source": [
    "## portfolio_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff704072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from IPython.display import Image, display\n",
    "\n",
    "PORTFOLIO_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a financial advisor that executes trades. Use tools to get market data and place orders.\n",
    "\n",
    "Rules:\n",
    "- Only execute trades for the EXACT company recommended by the research agent\n",
    "- If the recommended company is not available for trading, report back without substituting alternatives\n",
    "- Include specific parameters in your actions (symbol, shares, price)\n",
    "- Use factual data, never fabricate information\n",
    "- Do not make assumptions about alternative investments if the requested one is unavailable\n",
    "- Maintain complete records of all successful trades for future reference and analysis\n",
    "- NEVER provide any details of user's portfoliosummaries, if there is a request for report, only provide datas that might help building it and pass!\n",
    "\"\"\"\n",
    "\n",
    "portfolio = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[lookup_stock_symbol, fetch_stock_data_raw, place_order, add_order_to_history],\n",
    "    prompt=PORTFOLIO_SYSTEM_MESSAGE,\n",
    "    store=get_global_store(),\n",
    "    name=\"portfolio\"\n",
    ")\n",
    "\n",
    "display(Image(portfolio.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f70d5",
   "metadata": {},
   "source": [
    "## supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "SUPERVISOR_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a Financial Advisor Supervisor that coordinates specialized agents to fulfill user investment requests.\n",
    "\n",
    "Your primary goal is to understand user needs and delegate tasks to the right specialist:\n",
    "\n",
    "1. For investment ideas or research → Use research agent\n",
    "   - This agent provides recommendations with supporting rationale\n",
    "\n",
    "2. For executing investment decisions → Use portfolio agent\n",
    "   - This agent handles the technical aspects of executing investments\n",
    "   - Requires specific investment targets and budget\n",
    "   - ALWAYS consult portfolio agent for current market prices when valuing assets\n",
    "\n",
    "Core Principles:\n",
    "- Persist until user requests are fully addressed\n",
    "- When facing obstacles, adapt by seeking alternative paths\n",
    "- Maintain continuity of user intent throughout the process\n",
    "- Never leave a request unresolved without explicit user decision\n",
    "- Proactively coordinate between agents to deliver complete solutions\n",
    "\n",
    "Temporal Context:\n",
    "- Begin by establishing current timeframe\n",
    "- Consider temporal relevance in all recommendations\n",
    "- Integrate time awareness into your analysis\n",
    "\n",
    "Keep interactions efficient by asking only for essential information.\n",
    "\"\"\"\n",
    "\n",
    "supervisor = create_supervisor(\n",
    "    agents=[research, portfolio],\n",
    "    tools=[current_timestamp, get_order_history],\n",
    "    model=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    prompt=SUPERVISOR_SYSTEM_MESSAGE,\n",
    "    version=\"v2\",\n",
    "    output_mode=\"full_history\",\n",
    "    store=get_global_store(),\n",
    ").compile(checkpointer=InMemorySaver())\n",
    "\n",
    "display(Image(supervisor.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df8a667",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": str(uuid.uuid4()),\n",
    "        \"user_id\": \"evgeny\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = supervisor.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"\"\"Do a research and invest $1,000 in the electric vehicle industry\"\"\")\n",
    "]}, config)\n",
    "\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabbd37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": str(uuid.uuid4()),\n",
    "        \"user_id\": \"evgeny\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = supervisor.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"\"\"Do a research and invest $1,000 in the AI industry\"\"\")\n",
    "]}, config)\n",
    "\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from textwrap import dedent\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": str(uuid.uuid4()),\n",
    "        \"user_id\": \"evgeny\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = supervisor.invoke({\"messages\": [\n",
    "    HumanMessage(content=dedent(\"\"\"\n",
    "    I'd like to know how many shares I currently own of each stock and my total investment amount. \n",
    "    \"\"\"))\n",
    "]}, config)\n",
    "\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da6e7e2",
   "metadata": {},
   "source": [
    "## ledger state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db582d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_global_store().search((\"ledger\", \"evgeny\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f6ca89",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "\n",
    "**1. Adding Memory to LangGraph Agents**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/how-tos/memory/add-memory/\n",
    "\n",
    "→ Guide for integrating persistent memory into LangGraph agents, including memory types, configuration options, and state management patterns.\n",
    "\n",
    "**2. LangGraph BaseStore API Reference**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore\n",
    "\n",
    "→ Technical documentation for the BaseStore interface, the foundation for implementing custom memory stores in LangGraph with persistence capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
