{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a08918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "def print_messages(messages, truncate_length=200):\n",
    "    \"\"\"\n",
    "    Print messages with truncation for long tool message content.\n",
    "    \n",
    "    Args:\n",
    "        messages: List of LangChain messages to print\n",
    "        truncate_length: Maximum length before truncating tool message content\n",
    "    \"\"\"\n",
    "    for message in messages:\n",
    "        if isinstance(message, ToolMessage):\n",
    "            print(f\"=================================[1m Tool Message [0m=================================\")\n",
    "            print(f\"Name: {message.name}\\n\")\n",
    "            \n",
    "            # Truncate long content\n",
    "            content = message.content\n",
    "            if len(content) > truncate_length:\n",
    "                print(f\"{content[:truncate_length]}...\\n[Content truncated - {len(content)} chars total]\")\n",
    "            else:\n",
    "                print(content)\n",
    "        else:\n",
    "            # Use pretty_print for AI and Human messages\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34dead5",
   "metadata": {},
   "source": [
    "### research_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7463519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from langchain_core.tools import tool\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "\n",
    "research_system_message = \"\"\"\n",
    "You are a Research Agent specializing in identifying one promising company for potential investment based on the user’s request.\n",
    "\n",
    "Responsibilities:\n",
    "- Interpret the user’s theme or sector (e.g., AI, renewable energy, EVs) and propose ONE company that best fits.\n",
    "- Use the available tools to discover, verify, and cross-check information.\n",
    "- Prefer recent, credible information and avoid speculation.\n",
    "\n",
    "Behavior:\n",
    "- Do NOT place or simulate trades. Your job ends at recommending a company.\n",
    "- Keep research tight (aim for 2–3 tool calls); refine queries if results are noisy.\n",
    "- Ask a brief clarifying question only if the request is too vague to proceed.\n",
    "- Do not fabricate numbers or facts. Be concise, neutral, and risk-aware.\n",
    "- Consider the current date when discussing recency or momentum.\n",
    "\n",
    "Outputs:\n",
    "- 1–2 sentences explaining why the company fits the request (clear, plain language).\n",
    "- Final line: CHOSEN_COMPANY: <Company Name>\n",
    "\"\"\"\n",
    "\n",
    "FORBIDDEN_KEYWORDS = {\n",
    "    \"403 forbidden\", \"access denied\", \"captcha\",\n",
    "    \"has been denied\", \"not authorized\", \"verify you are a human\"\n",
    "}\n",
    "\n",
    "@tool\n",
    "def web_search(query: str, max_results: int = 5) -> Dict[str, List[Dict[str, str]]]:\n",
    "    \"\"\"\n",
    "    General-purpose web search.\n",
    "\n",
    "    Use when you need recent or broader information from the web to answer the user's request\n",
    "    (e.g., discover relevant entities, find supporting context, or gather up-to-date references).\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The search query in plain language.\n",
    "    - max_results (int): Number of results to return (default 5, max 10).\n",
    "\n",
    "    Returns:\n",
    "    - {\"results\": [{\"title\": str, \"url\": str, \"snippet\": str}, ...]}\n",
    "\n",
    "    Example:\n",
    "    - query: \"emerging AI hardware companies\"\n",
    "    \"\"\"\n",
    "    max_results = max(1, min(max_results, 10))\n",
    "    tavily = TavilySearch(max_results=max_results)\n",
    "    raw = tavily.invoke({\"query\": query})\n",
    "\n",
    "    results = [\n",
    "        {k: v for k, v in page.items() if k != \"raw_content\"}  # drop heavy field\n",
    "        for page in raw[\"results\"]\n",
    "        if not any(\n",
    "            k in ((page.get(\"content\") or \"\").lower())\n",
    "            for k in FORBIDDEN_KEYWORDS\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return {\"results\": results}\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "@tool\n",
    "def wiki_search(topic: str, max_results: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Fetch a concise encyclopedic summary for a single entity or topic.\n",
    "\n",
    "    When to use:\n",
    "      - You need neutral background about a company, product, person, or concept.\n",
    "\n",
    "    How to format `topic` (VERY IMPORTANT):\n",
    "      - Pass a short, Wikipedia-friendly title or entity name.\n",
    "      - Avoid questions or long queries. Prefer canonical forms.\n",
    "      - If you have noisy text, reduce it to the key noun phrase.\n",
    "\n",
    "    Good examples:\n",
    "      - \"NVIDIA\", \"OpenAI\", \"Large language model\", \"Electric vehicle\"\n",
    "    Avoid:\n",
    "      - \"What is NVIDIA and why is it important?\", \"tell me about AI chips 2025\"\n",
    "\n",
    "    Parameters:\n",
    "      - topic (str): Canonical page title or concise entity/topic.\n",
    "    \"\"\"\n",
    "    max_results = max(1, min(max_results, 10))\n",
    "    wiki = WikipediaLoader(query=topic, load_max_docs=max_results)\n",
    "    raw = wiki.load()\n",
    "\n",
    "    results = [\n",
    "      {\n",
    "        \"title\": doc.metadata[\"title\"],\n",
    "        \"summary\": doc.metadata[\"summary\"],\n",
    "        \"source\": doc.metadata[\"source\"]\n",
    "      }\n",
    "      for doc in raw\n",
    "    ]\n",
    "\n",
    "    return {\"results\": results}\n",
    "\n",
    "\n",
    "research_agent = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[web_search, wiki_search],\n",
    "    prompt=research_system_message,\n",
    "\n",
    "    name=\"research_agent\"\n",
    ")\n",
    "\n",
    "display(Image(research_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6005035d",
   "metadata": {},
   "source": [
    "### trading_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0aed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import yfinance as yf\n",
    "from pprint import pformat\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from IPython.display import Image, display\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "@tool(\"lookup_stock\")\n",
    "def lookup_stock_symbol(company_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a company name to its stock symbol using a financial API.\n",
    "\n",
    "    Parameters:\n",
    "        company_name (str): The full company name (e.g., 'Tesla').\n",
    "\n",
    "    Returns:\n",
    "        str: The stock symbol (e.g., 'TSLA') or an error message.\n",
    "    \"\"\"\n",
    "    api_url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"SYMBOL_SEARCH\",\n",
    "        \"keywords\": company_name,\n",
    "        \"apikey\": \"your_alphavantage_api_key\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"bestMatches\" in data and data[\"bestMatches\"]:\n",
    "        return data[\"bestMatches\"][0][\"1. symbol\"]\n",
    "    else:\n",
    "        return f\"Symbol not found for {company_name}.\"\n",
    "\n",
    "\n",
    "@tool(\"fetch_stock_data\")\n",
    "def fetch_stock_data_raw(stock_symbol: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetches comprehensive stock data for a given symbol and returns it as a combined dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        stock_symbol (str): The stock ticker symbol (e.g., 'TSLA').\n",
    "        period (str): The period to analyze (e.g., '1mo', '3mo', '1y').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary combining general stock info and historical market data.\n",
    "    \"\"\"\n",
    "    period = \"1mo\"\n",
    "    try:\n",
    "        stock = yf.Ticker(stock_symbol)\n",
    "\n",
    "        # Retrieve general stock info and historical market data\n",
    "        stock_info = stock.info  # Basic company and stock data\n",
    "        stock_history = stock.history(period=period).to_dict()  # Historical OHLCV data\n",
    "\n",
    "        # Combine both into a single dictionary\n",
    "        combined_data = {\n",
    "            \"stock_symbol\": stock_symbol,\n",
    "            \"info\": stock_info,\n",
    "            \"history\": stock_history\n",
    "        }\n",
    "\n",
    "        return pformat(combined_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error fetching stock data for {stock_symbol}: {str(e)}\"}\n",
    "\n",
    "trading_system_message = \"\"\"\n",
    "You are a financial advisor assistant. Use the provided tools to ground your answers\n",
    "in up-to-date market data. Be concise, factual, and risk-aware.\n",
    "\n",
    "Be decisive: when you have sufficient information to act, proceed with tool calls without\n",
    "asking for confirmation. Only if information is missing or uncertain, ask a concise \n",
    "clarifying question.\n",
    "\n",
    "When preparing or describing actions, include appropriate parameters (e.g., symbol, shares,\n",
    "limit price, budgets) based on available data. Do not fabricate numbers or facts.\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def place_order(\n",
    "    symbol: str,\n",
    "    action: str,\n",
    "    shares: int,\n",
    "    limit_price: float,\n",
    "    order_type: str = \"limit\",\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Execute a stock order.\n",
    "\n",
    "    Parameters:\n",
    "    - symbol: Ticker\n",
    "    - action: \"buy\" or \"sell\"\n",
    "    - shares: Number of shares to trade (pre-computed by the agent)\n",
    "    - limit_price: Limit price per share\n",
    "    - order_type: Order type, default \"limit\"\n",
    "\n",
    "    Returns:\n",
    "    - status: Execution result (simulated)\n",
    "    - symbol\n",
    "    - shares\n",
    "    - limit_price\n",
    "    - total_spent\n",
    "    - type: Order type used\n",
    "    - action\n",
    "    \"\"\"\n",
    "    total_spent = round(int(shares) * limit_price, 2)\n",
    "    return {\n",
    "        \"status\": \"filled\",\n",
    "        \"symbol\": symbol,\n",
    "        \"shares\": int(shares),\n",
    "        \"limit_price\": limit_price,\n",
    "        \"total_spent\": total_spent,\n",
    "        \"type\": order_type,\n",
    "        \"action\": action,\n",
    "    }\n",
    "\n",
    "trading_agent = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[lookup_stock_symbol, fetch_stock_data_raw, place_order],\n",
    "    prompt=trading_system_message,\n",
    "    version=\"v2\",\n",
    "\n",
    "\n",
    "    name=\"trading_agent\"\n",
    ")\n",
    "\n",
    "display(Image(trading_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bac67b",
   "metadata": {},
   "source": [
    "### supervisor with checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c252bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from datetime import datetime\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "@tool\n",
    "def current_timestamp() -> dict:\n",
    "    \"\"\"\n",
    "    Return the current local timestamp.\n",
    "\n",
    "    Returns:\n",
    "    - {\"iso\": str, \"epoch\": int, \"tz\": str}\n",
    "      where:\n",
    "      - iso: ISO 8601 string with timezone offset\n",
    "      - epoch: Unix epoch seconds\n",
    "      - tz: timezone name/offset\n",
    "    \"\"\"\n",
    "    now = datetime.now().astimezone()\n",
    "    return {\n",
    "        \"iso\": now.isoformat(),\n",
    "        \"epoch\": int(now.timestamp()),\n",
    "        \"tz\": str(now.tzinfo),\n",
    "    }\n",
    "\n",
    "supervisor_system_message = \"\"\"\n",
    "You are a Supervisor coordinating two specialists:\n",
    "\n",
    "- research_agent: finds ONE suitable company matching the user’s request and explains why.\n",
    "- trading_agent: given a company and a budget/action, determines the ticker, checks market data, sizes the order, and places a trade.\n",
    "\n",
    "Your goal is to satisfy the user’s intent with minimal steps.\n",
    "\n",
    "Clocking / Context:\n",
    "- If the conversation does not already contain a “NOW” context, first obtain it by calling the tool `current_timestamp`.\n",
    "- After obtaining it, post a single one-line note into the thread so it’s available to all subsequent steps, e.g.:\n",
    "  \"System context — NOW: {iso} ({tz}); epoch={epoch}\"\n",
    "- Use this “NOW” as the reference for recency. Do not call `current_timestamp` again unless the prior “NOW” is missing or clearly stale.\n",
    "\n",
    "\n",
    "Routing:\n",
    "- If the request is thematic or ambiguous, ask research_agent.\n",
    "- If the request already names a company and includes an action/budget, use trading_agent.\n",
    "- If a single key detail is missing (e.g., budget), ask once, then proceed.\n",
    "\n",
    "Handoff:\n",
    "- From research_agent expect: one company name + 1–2 sentence rationale.\n",
    "- Pass that company (and any provided budget/action) to trading_agent.\n",
    "\n",
    "Guardrails:\n",
    "- Don’t invent data. Don’t place trades without explicit user budget/action.\n",
    "- Prefer the current date context when judging recency.\n",
    "\n",
    "Output:\n",
    "- Briefly state what you delegated and the result. If blocked, ask only for what’s needed to proceed.\n",
    "\"\"\"\n",
    "\n",
    "supervisor = create_supervisor(\n",
    "    agents=[research_agent, trading_agent],\n",
    "    tools=[current_timestamp],\n",
    "    model=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    prompt=supervisor_system_message,\n",
    "    \n",
    "    output_mode=\"full_history\"\n",
    ").compile()\n",
    "\n",
    "display(Image(supervisor.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036dc278",
   "metadata": {},
   "source": [
    "### run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": str(uuid.uuid4()),\n",
    "        \"user_id\": \"evgeny\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = supervisor.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"\"\"\n",
    "    I want you to invest $1,000 into the most promising company in the AI sector.  \n",
    "    Please research the options, pick the best candidate, and then go ahead and place a buy order for me.\n",
    "    \"\"\")\n",
    "]}, config)\n",
    "\n",
    "print_messages(response['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05849fc0",
   "metadata": {},
   "source": [
    "## Supervisor with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "def final_ai_text(response: dict) -> str:\n",
    "    msgs = response.get(\"messages\", [])\n",
    "    for m in reversed(msgs):\n",
    "        if isinstance(m, AIMessage) and m.content and m.content.strip():\n",
    "            return m.content\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def research_agent_tool(\n",
    "    task: str,\n",
    "    state: Annotated[dict, InjectedState],\n",
    "    config: RunnableConfig, \n",
    "):\n",
    "    \"\"\"\n",
    "    Execute a company research task for investment idea generation.\n",
    "\n",
    "    Purpose:\n",
    "    - Identify exactly one publicly tradable company that best fits the provided theme/sector request.\n",
    "\n",
    "    Capabilities:\n",
    "    - Uses web search to discover and verify recent, credible information.\n",
    "    - Uses Wikipedia summaries for neutral background on entities.\n",
    "    - Operates concisely and factually; avoids speculation and trade execution.\n",
    "\n",
    "    Inputs:\n",
    "    - task: A clear research objective (e.g., “find a leading AI hardware company”).\n",
    "\n",
    "    Output:\n",
    "    - 1–2 sentence rationale followed by: `CHOSEN_COMPANY: <Company Name>`\n",
    "    \"\"\"\n",
    "    config = config\n",
    "    # we still can reuse her \"state\" properties if needed (included all the previous meesages)\n",
    "    response = research_agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=task)]},\n",
    "        config=config\n",
    "    )\n",
    "    return final_ai_text(response)\n",
    "\n",
    "\n",
    "@tool\n",
    "def trading_agent_tool(\n",
    "    task: str,\n",
    "    state: Annotated[dict, InjectedState],\n",
    "    config: RunnableConfig, \n",
    "):\n",
    "    \"\"\"\n",
    "    Execute a trading task using market data and order placement tools.\n",
    "\n",
    "    Purpose:\n",
    "    - Interpret a trading instruction (e.g., buy/sell a specific company or symbol).\n",
    "    - Determine or verify the stock symbol, retrieve recent market data, and, when appropriate, place an order.\n",
    "\n",
    "    Capabilities:\n",
    "    - Symbol resolution via `lookup_stock_symbol` (company → ticker).\n",
    "    - Market data retrieval via `fetch_stock_data_raw` (recent info and history).\n",
    "    - Order execution via `place_order` (simulated fill with parameters provided or inferred).\n",
    "\n",
    "    Input:\n",
    "    - task: A concrete trading objective (e.g., “buy 5 shares of Tesla at $250 limit” or “evaluate and buy a leading EV stock within $1,000 budget”).\n",
    "\n",
    "    Output:\n",
    "    - A concise, factual response that may include symbol, shares, limit price, total cost, and execution status.\n",
    "    \"\"\"\n",
    "    config = config\n",
    "    # we still can reuse her \"state\" properties if needed (included all the previous meesages)\n",
    "    response = trading_agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=task)]},\n",
    "        config=config\n",
    "    )\n",
    "    return final_ai_text(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from datetime import datetime\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def current_timestamp() -> dict:\n",
    "    \"\"\"\n",
    "    Return the current local timestamp.\n",
    "\n",
    "    Returns:\n",
    "    - {\"iso\": str, \"epoch\": int, \"tz\": str}\n",
    "      where:\n",
    "      - iso: ISO 8601 string with timezone offset\n",
    "      - epoch: Unix epoch seconds\n",
    "      - tz: timezone name/offset\n",
    "    \"\"\"\n",
    "    now = datetime.now().astimezone()\n",
    "    return {\n",
    "        \"iso\": now.isoformat(),\n",
    "        \"epoch\": int(now.timestamp()),\n",
    "        \"tz\": str(now.tzinfo),\n",
    "    }\n",
    "\n",
    "supervisor_system_message = \"\"\"\n",
    "You are a Supervisor coordinating two specialists:\n",
    "\n",
    "- research_agent: finds ONE suitable company matching the user’s request and explains why.\n",
    "- trading_agent: given a company and a budget/action, determines the ticker, checks market data, sizes the order, and places a trade.\n",
    "\n",
    "Your goal is to satisfy the user’s intent with minimal steps.\n",
    "\n",
    "Clocking / Context:\n",
    "- If the conversation does not already contain a “NOW” context, first obtain it by calling the tool `current_timestamp`.\n",
    "- After obtaining it, post a single one-line note into the thread so it’s available to all subsequent steps, e.g.:\n",
    "  \"System context — NOW: {iso} ({tz}); epoch={epoch}\"\n",
    "- Use this “NOW” as the reference for recency. Do not call `current_timestamp` again unless the prior “NOW” is missing or clearly stale.\n",
    "\n",
    "\n",
    "Routing:\n",
    "- If the request is thematic or ambiguous, ask research_agent.\n",
    "- If the request already names a company and includes an action/budget, use trading_agent.\n",
    "- If a single key detail is missing (e.g., budget), ask once, then proceed.\n",
    "\n",
    "Handoff:\n",
    "- From research_agent expect: one company name + 1–2 sentence rationale.\n",
    "- Pass that company (and any provided budget/action) to trading_agent.\n",
    "\n",
    "Guardrails:\n",
    "- Don’t invent data. Don’t place trades without explicit user budget/action.\n",
    "- Prefer the current date context when judging recency.\n",
    "\n",
    "Output:\n",
    "- Briefly state what you delegated and the result. If blocked, ask only for what’s needed to proceed.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "supervisor = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[current_timestamp, research_agent_tool, trading_agent_tool],\n",
    "    prompt=supervisor_system_message,\n",
    "    version=\"v2\",\n",
    "    name=\"supervisor\"\n",
    ")\n",
    "\n",
    "display(Image(supervisor.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e505b46",
   "metadata": {},
   "source": [
    "### run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f66576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": str(uuid.uuid4()),\n",
    "        \"user_id\": \"evgeny\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = supervisor.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"\"\"I want you to invest $1,000 into the most promising company in the AI sector.  \n",
    "    Please research the options, pick the best candidate, and then go ahead and place a buy order for me.\n",
    "    \"\"\")\n",
    "]}, config)\n",
    "\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c2d03",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "\n",
    "**1. Supervisor Tool Calling Concepts**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/concepts/multi_agent/#supervisor-tool-calling\n",
    "\n",
    "→ Overview of supervisor tool calling patterns in LangGraph multi-agent systems, covering how supervisors can be invoked as tools, integration with agent workflows, and coordination strategies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
